# ğŸ¤– MCP Server

This is the backend **MCP Server** (Modular Cognitive Processor) for routing AI tools like summarization, knowledgebase search, and agent-based responses.

Deployed using **FastAPI** with **Server-Sent Events (SSE)** to support real-time streaming.

---

## ğŸ”§ Features

- ğŸ§  Modular tool execution via `ClientSession`
- ğŸ” Live communication via SSE (`/sse`)
- ğŸŒ Easily deployable to Render.com or Hugging Face Spaces
- ğŸ¤– Works with frontends like Gradio and ADK Agents

---

## ğŸš€ Deployment on Render

1. **Clone and push to GitHub**:

    ```bash
    git clone https://github.com/YOUR_USERNAME/mcp-server.git
    cd mcp-server
    git push origin main
    ```

2. **Connect to [Render.com](https://render.com)**:
    - Choose **"New Web Service"**
    - Link your GitHub repo
    - Use the following:

      | Key              | Value                                 |
      |------------------|---------------------------------------|
      | Environment      | Python                                |
      | Build Command    | `pip install -r requirements.txt`     |
      | Start Command    | `uvicorn server:app --host 0.0.0.0 --port 10000` |
      | Instance Type    | Free                                  |

3. **Access endpoint**:  
    Your server will be hosted at:  
    `https://your-app-name.onrender.com/sse`

---

## ğŸ“‚ Project Structure

```bash
mcp-server/
â”‚
â”œâ”€â”€ server.py           # FastAPI server with SSE endpoint
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Procfile            # Start command for Render
â””â”€â”€ README.md           # You're here!
